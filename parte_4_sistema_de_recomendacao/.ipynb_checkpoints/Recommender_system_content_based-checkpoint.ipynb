{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funded-object",
   "metadata": {},
   "source": [
    "## <div align=\"center\"><b><h3> Content Based Recommender System </h3></b></div>\n",
    "<img src=\"recommendation_system_1.jpg\" width=\"350\">\n",
    "Sistemas de recomendação são aplicações de data science bastante populares atualmente. De modo geral, com base em alguma preferência do usuário, são sugeridos produtos/serviços semelhantes ou produtos/serviços que usuários semelhantes escolheram anteriormente. Os tipos mais comuns de motores de recomendação:\n",
    "\n",
    "* **Filtros colaborativos:** são baseados no comportamento de usuários semelhantes, e recomendam produtos/serviços a um determinado usuário conforme os gostos de outros usuários semelhantes a ele;\n",
    "* **Filtros baseados em conteúdo:** são baseados em informações das preferências do perfil do usuário, ou seja, sugerem outros itens conforme itens similares já adquiridos anteriormente;\n",
    "* **Sistemas híbridos:** é uma combinação dos dois sistemas citados acima.\n",
    "\n",
    "Neste notebook, será apresentada a construção de um sistema de recomendação básico, baseado em conteúdo, a partir de artigos divulgados no Medium, onde o usuário pode informar o título de um artigo e com base no título, autor e publicação serão sugeridos artigos semelhantes.\n",
    "\n",
    "### Coleta dos dados\n",
    "Os dados foram coletados no dia 03/02/2021 a partir de 7 tags que mais se relacionam com o tema inteligência artificial, são elas: 'AI', 'artificial-intelligence', 'data', 'data-science', 'deep-learning', 'machine-learning', 'neural-networks'\n",
    "Foram extraídas as publicações diárias no período de 01/01/2020 a 31/12/2020, estes dados foram tratados (link) e o dataset final apresenta a seguinte estrutura.\n",
    "\n",
    "### Estrutura dos dados\n",
    "* Title - título do artigo no card de extração\n",
    "* Subtitle - subtítulo do artigo no card de extração\n",
    "* Image (yes/no)- indica se o artigo possui uma imagem de preview no card de extração\n",
    "* Author - autor do artigo\n",
    "* Publication - título da publicação à qual o artigo está vinculada, para o caso de artigos independentes está marcado como \"No * * publication\"\n",
    "* Year - Month - Day - data em que o artigo foi publicado\n",
    "* Tag - Tag à qual o artigo foi vinculado, lembrando que um artigo pode ser vinculado à até 5 tags\n",
    "* Reading Time- tempo de leitura do artigo\n",
    "* Claps - número de aplausos que o artigo recebeu até a data de coleta dos dados\n",
    "* Comment (yes/no) - indica se a entrda é um comentário em um outro artigo\n",
    "* Story Url - link para o artigo\n",
    "* Author URL - link para a homepage do autor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-mississippi",
   "metadata": {},
   "source": [
    "### Carregando a libraries necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "owned-telephone",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subtle-appeal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 989 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "articles = pd.read_csv('D:/Documentos/Projetos/Sistemas_de_recomendacao/Scrap_medium/by_tag/recommender_csv/medium_articles_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "square-morning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to go from BayesTheorem to Bayesian Inference</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>JimSpark</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>10</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/how-to-go-from-bayestheorem-to-bayesian-inference-2a75ac64ec07</td>\n",
       "      <td>https://towardsdatascience.com/@jimip6c12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autoencoders: Overview of Research and Applications</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Branislav Holl nder</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>10</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/autoencoders-overview-of-research-and-applications-86135f7c0d35</td>\n",
       "      <td>https://towardsdatascience.com/@branislav.hollander</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regarding SingularityNET and the Recent KuCoin Hack</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Ben Goertzel</td>\n",
       "      <td>SingularityNET</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>8</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://blog.singularitynet.io/regarding-singularitynet-and-the-recent-kucoin-hack-fee601b8ad8c</td>\n",
       "      <td>https://blog.singularitynet.io/@ben_90344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understand Machine Learning with One Article</td>\n",
       "      <td>Lets dive into one of the most mind-blowing and demanded</td>\n",
       "      <td>1</td>\n",
       "      <td>Julian Herrera</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>11</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/understand-machine-learning-with-one-article-7399f6b9c5ad</td>\n",
       "      <td>https://towardsdatascience.com/@julianh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The End of the World</td>\n",
       "      <td>Below is a conversation I had with OpenAIs GPT-3s language model. I gave GPT-3 the role of Wise Being. All of the</td>\n",
       "      <td>1</td>\n",
       "      <td>Kirk Ouimet</td>\n",
       "      <td>No publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@kirkouimet/the-end-of-the-world-5457c252523</td>\n",
       "      <td>https://medium.com/@kirkouimet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Differential PrivacyNoise adding Mechanisms</td>\n",
       "      <td>Differential Privacy Basics Series(Part5)</td>\n",
       "      <td>1</td>\n",
       "      <td>shaistha fathima</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>10</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://becominghuman.ai/differential-privacy-noise-adding-mechanisms-ede242dcbb2e</td>\n",
       "      <td>https://becominghuman.ai/@shaistha24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Whitewashing tech: Why the erasures of the past matter today</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>AI Now Institute</td>\n",
       "      <td>No publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>7</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@AINowInstitute/whitewashing-tech-why-the-erasures-of-the-past-matter-today-166d0d5e2789</td>\n",
       "      <td>https://medium.com/@AINowInstitute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is Strong Artificial Intelligence Possible? No</td>\n",
       "      <td>We are analyzing the most hype topic of the modern days, whichto our mind</td>\n",
       "      <td>1</td>\n",
       "      <td>Denis Nushtaev</td>\n",
       "      <td>Cantor s Paradise</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/cantors-paradise/why-strong-ai-is-not-possible-85e65a6c4f3e</td>\n",
       "      <td>https://medium.com/@nushtaev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YOLOV4 Partie 1:  la pointe de la dtection dobjet.</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Maxime Carrere</td>\n",
       "      <td>Scalian</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/scalian/comment-fonctionne-yolov4-la-vitesse-et-la-pr%C3%A9cision-maximale-en-d%C3%A9tection-dobjet-43724ab8786</td>\n",
       "      <td>https://medium.com/@maxime.carrere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Testing TikToks Multi-Billion Dollar Algorithm</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Alan Mendelevich</td>\n",
       "      <td>&lt;/dev&gt; diaries</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225</td>\n",
       "      <td>https://blog.ailon.org/@ailon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Title  \\\n",
       "0             How to go from BayesTheorem to Bayesian Inference   \n",
       "1           Autoencoders: Overview of Research and Applications   \n",
       "2           Regarding SingularityNET and the Recent KuCoin Hack   \n",
       "3                  Understand Machine Learning with One Article   \n",
       "4                                          The End of the World   \n",
       "5                   Differential PrivacyNoise adding Mechanisms   \n",
       "6  Whitewashing tech: Why the erasures of the past matter today   \n",
       "7                Is Strong Artificial Intelligence Possible? No   \n",
       "8            YOLOV4 Partie 1:  la pointe de la dtection dobjet.   \n",
       "9                Testing TikToks Multi-Billion Dollar Algorithm   \n",
       "\n",
       "                                                                                                            Subtitle  \\\n",
       "0                                                                                                        No subtitle   \n",
       "1                                                                                                        No subtitle   \n",
       "2                                                                                                        No subtitle   \n",
       "3                                                           Lets dive into one of the most mind-blowing and demanded   \n",
       "4  Below is a conversation I had with OpenAIs GPT-3s language model. I gave GPT-3 the role of Wise Being. All of the   \n",
       "5                                                                          Differential Privacy Basics Series(Part5)   \n",
       "6                                                                                                        No subtitle   \n",
       "7                                         We are analyzing the most hype topic of the modern days, whichto our mind    \n",
       "8                                                                                                        No subtitle   \n",
       "9                                                                                                        No subtitle   \n",
       "\n",
       "   Image               Author  \\\n",
       "0      1             JimSpark   \n",
       "1      1  Branislav Holl nder   \n",
       "2      1         Ben Goertzel   \n",
       "3      1       Julian Herrera   \n",
       "4      1          Kirk Ouimet   \n",
       "5      1     shaistha fathima   \n",
       "6      1     AI Now Institute   \n",
       "7      1       Denis Nushtaev   \n",
       "8      1       Maxime Carrere   \n",
       "9      1     Alan Mendelevich   \n",
       "\n",
       "                                        Publication  Year  Month  Day Tag  \\\n",
       "0                              Towards Data Science  2020     10    1  AI   \n",
       "1                              Towards Data Science  2020     10    1  AI   \n",
       "2                                    SingularityNET  2020     10    1  AI   \n",
       "3                              Towards Data Science  2020     10    1  AI   \n",
       "4                                    No publication  2020     10    1  AI   \n",
       "5  Becoming Human: Artificial Intelligence Magazine  2020     10    1  AI   \n",
       "6                                    No publication  2020     10    1  AI   \n",
       "7                                 Cantor s Paradise  2020     10    1  AI   \n",
       "8                                           Scalian  2020     10    1  AI   \n",
       "9                                    </dev> diaries  2020     10    1  AI   \n",
       "\n",
       "   Reading_Time  Claps  Comment  \\\n",
       "0            10   68.0        0   \n",
       "1            10  129.0        0   \n",
       "2             8  320.0        0   \n",
       "3            11   67.0        0   \n",
       "4             5   60.0        0   \n",
       "5            10   52.0        0   \n",
       "6             7  164.0        0   \n",
       "7            20   60.0        0   \n",
       "8             8    7.0        0   \n",
       "9             5   10.0        0   \n",
       "\n",
       "                                                                                                                                  url  \\\n",
       "0                                       https://towardsdatascience.com/how-to-go-from-bayestheorem-to-bayesian-inference-2a75ac64ec07   \n",
       "1                                      https://towardsdatascience.com/autoencoders-overview-of-research-and-applications-86135f7c0d35   \n",
       "2                                     https://blog.singularitynet.io/regarding-singularitynet-and-the-recent-kucoin-hack-fee601b8ad8c   \n",
       "3                                            https://towardsdatascience.com/understand-machine-learning-with-one-article-7399f6b9c5ad   \n",
       "4                                                                     https://medium.com/@kirkouimet/the-end-of-the-world-5457c252523   \n",
       "5                                                  https://becominghuman.ai/differential-privacy-noise-adding-mechanisms-ede242dcbb2e   \n",
       "6                         https://medium.com/@AINowInstitute/whitewashing-tech-why-the-erasures-of-the-past-matter-today-166d0d5e2789   \n",
       "7                                                      https://medium.com/cantors-paradise/why-strong-ai-is-not-possible-85e65a6c4f3e   \n",
       "8  https://medium.com/scalian/comment-fonctionne-yolov4-la-vitesse-et-la-pr%C3%A9cision-maximale-en-d%C3%A9tection-dobjet-43724ab8786   \n",
       "9                                                   https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225   \n",
       "\n",
       "                                            Author_url  \n",
       "0            https://towardsdatascience.com/@jimip6c12  \n",
       "1  https://towardsdatascience.com/@branislav.hollander  \n",
       "2            https://blog.singularitynet.io/@ben_90344  \n",
       "3              https://towardsdatascience.com/@julianh  \n",
       "4                       https://medium.com/@kirkouimet  \n",
       "5                 https://becominghuman.ai/@shaistha24  \n",
       "6                   https://medium.com/@AINowInstitute  \n",
       "7                         https://medium.com/@nushtaev  \n",
       "8                   https://medium.com/@maxime.carrere  \n",
       "9                        https://blog.ailon.org/@ailon  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-diagnosis",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **ALERTA!!!** </span> **Infelizmente, devido a limitações de capacidade computacional, só irei trabalhar com os últimos 4 meses da base de dados. Entretanto, para fins acadêmicos já vale como treinamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "returning-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dec = articles[(articles.Month >= 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "devoted-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51784, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-potato",
   "metadata": {},
   "source": [
    "Como a base está na granularidade artigo-tag é necessário remover os artigos duplicados em mais de uma tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spiritual-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dec = articles_dec.drop_duplicates(subset=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "radical-remark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33472, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adopted-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dec = articles_dec.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-block",
   "metadata": {},
   "source": [
    "### Computando a matriz TF-IDF\n",
    "Instanciando um objeto TF-IDF Vectorizer. Também será definida a remoção de todas as stopwords em inglês, uma vez que a maioria dos artigos está nessa língua, de caracteres especiais e passando os textos para caixa baixa. Neste caso, a matriz esparsa será criada utilizando tanto unigram quanto bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solved-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', strip_accents='unicode', lowercase=True, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-found",
   "metadata": {},
   "source": [
    "Substituindo NaN com uma string em branco e excluindo espaços em branco indesejados no início e final do título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strong-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_dec['Title'] = articles_dec['Title'].fillna('').str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-enclosure",
   "metadata": {},
   "source": [
    "Contruindo a matriz TF-IDF, através do treino e transformação do corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rotary-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf.fit_transform(articles_dec['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-percentage",
   "metadata": {},
   "source": [
    "Checando o shape da matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "standard-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33472, 122316)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-pakistan",
   "metadata": {},
   "source": [
    "### Computando a matriz de similaridades\n",
    "Existem diversas formas de computar a similaridade entre elementos (distância de Manhattan, euclidiana, Jaccard, coseno, etc). Cada método funcionará em diferentes cenários, sendo assim é uma boa ideia experimentar diferentes métricas e observar os resultados.\n",
    "Entretanto, neste caso vamos computar as similaridades via cosseno, uma vez que este método é independente da magnitude e é relativamente rápido de calcular. Basicamente, ele mede a similaridade entre dois vetores utilizando o cosseno do ângulo entre eles, com valores variando de 0 a 1, com 1 indicando que os dois vetores estão indo na mesma direção. Matematicamente, o cálculo da similaridade é definido como abaixo:\n",
    "\n",
    "$$\n",
    "   similaridade = cos(x,y) = \\frac{x \\cdot y}{||x|| ||y||} = \\frac{\\sum_{i=1}^{n} x_i \\cdot y_i}{\\sqrt{\\sum_{i=1}^{n}x_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n}y_i^2}}\n",
    "$$\n",
    "\n",
    "Em nosso caso, vamos utilizar a função **cosine_similarity** da biblioteca **scikit-learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crucial-space",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33472, 33472)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computando a matriz de similaridades e verificando o shape\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vital-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construindo um mapa reverso dos índices e títulos dos artigos\n",
    "indices = pd.Series(articles_dec.index, index=articles_dec['Title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "attended-purchase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "How to go from BayesTheorem to Bayesian Inference               0\n",
       "Autoencoders: Overview of Research and Applications             1\n",
       "Regarding SingularityNET and the Recent KuCoin Hack             2\n",
       "Understand Machine Learning with One Article                    3\n",
       "The End of the World                                            4\n",
       "Differential PrivacyNoise adding Mechanisms                     5\n",
       "Whitewashing tech: Why the erasures of the past matter today    6\n",
       "Is Strong Artificial Intelligence Possible? No                  7\n",
       "YOLOV4 Partie 1:  la pointe de la dtection dobjet.              8\n",
       "Testing TikToks Multi-Billion Dollar Algorithm                  9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mental-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta função pega o título de um artigo e retorna os mais similares a ele, de acordo com a matriz de \n",
    "# similaridades calculada acima\n",
    "def get_recommendations(title, sim_matrix):\n",
    "    # Retornando o índice do artigo que corresponde ao título\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Retornando os artigos mais similares\n",
    "    sim_scores = list(enumerate(sim_matrix[idx]))\n",
    "\n",
    "    # Ordenando os artigos com base nos scores de similaridade, em ordem decrescente\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Retornando os scores dos 10 artigos mais similares\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Pegando os índices destes artigos\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Pegando os metadados do artigo pesquisado, para exibir\n",
    "    meta_list = articles_dec[articles_dec[\"Title\"] == title][['Title', 'Author', 'Publication']].values.tolist()\n",
    "\n",
    "    print('')\n",
    "    print('\\033[1m'+\"Artigo pesquisado:\"+\"\\033[0m\", meta_list[0][0])\n",
    "    print('\\033[1m'+\"Autor:\"+\"\\033[0m\", meta_list[0][1])\n",
    "    print('\\033[1m'+\"Publicação:\"+\"\\033[0m\", meta_list[0][2])\n",
    "    print('')\n",
    "    print('\\033[91m'+'\\033[1m'+'Top 10 artigos recomendados:'+\"\\033[0m\")\n",
    "    return articles_dec[['Title', 'Author', 'Publication', 'Claps']].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "binary-senior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Data Quest Tool at Hike', 'Hike', 'Hike Blog'],\n",
       " ['Standing with Dr. Timnit Gebru#ISupportTimnit #BelieveBlackWomen',\n",
       "  'Google Walkout For Real Change',\n",
       "  'No publication'],\n",
       " ['Read the Email That Led to the Exit of Google A.I. Ethicist Timnit Gebru',\n",
       "  'Dave Gershgorn',\n",
       "  'OneZero'],\n",
       " ['Why You Shouldnt Use, Gramerly', 'JL Matthews', 'Slackjaw'],\n",
       " ['Research on information quality and reliability of sources in Wikipedia',\n",
       "  'W odzimierz Lewoniewski',\n",
       "  'Wikipedia quality'],\n",
       " ['Ser que estamos a ser vigiados por um Big Brother?',\n",
       "  'Rita Luz',\n",
       "  'No publication'],\n",
       " ['AI in Healthcare', 'Tejas Kachare', 'No publication'],\n",
       " ['The Roadmap of Mathematics for Deep Learning',\n",
       "  'Tivadar Danka',\n",
       "  'Towards Data Science'],\n",
       " ['Build a global decentralized multi-agent system: Join and participate in our testnet program',\n",
       "  'Fetch.ai',\n",
       "  'Fetch.ai'],\n",
       " ['Fetch.ai Community AMA Recap (9th October 2020)', 'Fetch.ai', 'Fetch.ai']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordenando por popularidade (do mais popular)\n",
    "# criando lista dos 10 mais populares do nosso conjunto\n",
    "pop_articles = articles_dec.sort_values('Claps', ascending=False)[['Title', 'Author', 'Publication']].values.tolist()[1:11]\n",
    "pop_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "innovative-correction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mArtigo pesquisado:\u001b[0m The Roadmap of Mathematics for Deep Learning\n",
      "\u001b[1mAutor:\u001b[0m Tivadar Danka\n",
      "\u001b[1mPublicação:\u001b[0m Towards Data Science\n",
      "\n",
      "\u001b[91m\u001b[1mTop 10 artigos recomendados:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Claps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27102</th>\n",
       "      <td>The Mathematics Behind Deep Learning</td>\n",
       "      <td>Trist'n Joseph</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>The Mathematics of Deep Learning Optimizations- part 2</td>\n",
       "      <td>Charlie Masters</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>The Mathematics of Deep-learning Optimisations- part 1</td>\n",
       "      <td>Charlie Masters</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Ilexa Yardley</td>\n",
       "      <td>The Circular Theory</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12102</th>\n",
       "      <td>What is Deep Learning?</td>\n",
       "      <td>Dieter Jordens</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16217</th>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Thanaphat Popathom</td>\n",
       "      <td>No publication</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24600</th>\n",
       "      <td>The Deep Learning</td>\n",
       "      <td>Arun Addagatla</td>\n",
       "      <td>No publication</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11857</th>\n",
       "      <td>Complete Deep Learning Roadmap</td>\n",
       "      <td>Akash kumar</td>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19209</th>\n",
       "      <td>Machine Learning, Deep Learning</td>\n",
       "      <td>Laura L pez</td>\n",
       "      <td>No publication</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24895</th>\n",
       "      <td>#2 Machine Learning and Deep Learning</td>\n",
       "      <td>Prabhat</td>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Title  \\\n",
       "27102                    The Mathematics Behind Deep Learning   \n",
       "9286   The Mathematics of Deep Learning Optimizations- part 2   \n",
       "9288   The Mathematics of Deep-learning Optimisations- part 1   \n",
       "2920                                            Deep Learning   \n",
       "12102                                  What is Deep Learning?   \n",
       "16217                                           Deep Learning   \n",
       "24600                                       The Deep Learning   \n",
       "11857                          Complete Deep Learning Roadmap   \n",
       "19209                         Machine Learning, Deep Learning   \n",
       "24895                   #2 Machine Learning and Deep Learning   \n",
       "\n",
       "                   Author                                       Publication  \\\n",
       "27102      Trist'n Joseph                              Towards Data Science   \n",
       "9286      Charlie Masters  Becoming Human: Artificial Intelligence Magazine   \n",
       "9288      Charlie Masters  Becoming Human: Artificial Intelligence Magazine   \n",
       "2920        Ilexa Yardley                               The Circular Theory   \n",
       "12102      Dieter Jordens                              Towards Data Science   \n",
       "16217  Thanaphat Popathom                                    No publication   \n",
       "24600      Arun Addagatla                                    No publication   \n",
       "11857         Akash kumar                                  Analytics Vidhya   \n",
       "19209         Laura L pez                                    No publication   \n",
       "24895             Prabhat                                  Analytics Vidhya   \n",
       "\n",
       "       Claps  \n",
       "27102  311.0  \n",
       "9286    55.0  \n",
       "9288    60.0  \n",
       "2920     0.0  \n",
       "12102   42.0  \n",
       "16217    0.0  \n",
       "24600    9.0  \n",
       "11857   10.0  \n",
       "19209   15.0  \n",
       "24895   54.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Roadmap of Mathematics for Deep Learning', cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-groove",
   "metadata": {},
   "source": [
    "O recomendador realizou um trabalho razoável em encontrar artigos com títulos similares. Entretanto, talvez ainda possamos melhorar a qualidade. Pois, pessoas que leram determinado artigo podem também ficar interessadas em mais artigos do mesmo autor, por exemplo, o que não está sendo capturado por este recomendador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-solomon",
   "metadata": {},
   "source": [
    "### Gerando um novo recomendador que leva mais features em consideração\n",
    "Vamos analisar como fica a qualidade do recomendador com inserção de outras features a fim de capturar mais detalhes. Neste caso, além do título dos artigos, iremos utilizar, também, o autor e a publicação através da qual o mesmo foi divulgado.\n",
    "Para isso, precisaremos converter essas duas últimas features para minúsculas e remover espaços em branco para que o vetorizador não conte o \"John\" de John Perapras e John Kundycki como os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "union-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a mastriz de similaridades anterior, por motivo de limitação na capacidade computacional\n",
    "del cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vital-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter todas as strings para minúsculas e remover espaços em branco\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opponent-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função às variáveis Author e Publication\n",
    "features = ['Author', 'Publication']#'Title', \n",
    "\n",
    "for feature in features:\n",
    "    articles_dec[feature+'_clean'] = articles_dec[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sporting-british",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "      <th>Author_clean</th>\n",
       "      <th>Publication_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to go from BayesTheorem to Bayesian Inference</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>JimSpark</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>10</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/how-to-go-from-bayestheorem-to-bayesian-inference-2a75ac64ec07</td>\n",
       "      <td>https://towardsdatascience.com/@jimip6c12</td>\n",
       "      <td>jimspark</td>\n",
       "      <td>towardsdatascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autoencoders: Overview of Research and Applications</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Branislav Holl nder</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>10</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/autoencoders-overview-of-research-and-applications-86135f7c0d35</td>\n",
       "      <td>https://towardsdatascience.com/@branislav.hollander</td>\n",
       "      <td>branislavhollnder</td>\n",
       "      <td>towardsdatascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regarding SingularityNET and the Recent KuCoin Hack</td>\n",
       "      <td>No subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Ben Goertzel</td>\n",
       "      <td>SingularityNET</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>8</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://blog.singularitynet.io/regarding-singularitynet-and-the-recent-kucoin-hack-fee601b8ad8c</td>\n",
       "      <td>https://blog.singularitynet.io/@ben_90344</td>\n",
       "      <td>bengoertzel</td>\n",
       "      <td>singularitynet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understand Machine Learning with One Article</td>\n",
       "      <td>Lets dive into one of the most mind-blowing and demanded</td>\n",
       "      <td>1</td>\n",
       "      <td>Julian Herrera</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>11</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/understand-machine-learning-with-one-article-7399f6b9c5ad</td>\n",
       "      <td>https://towardsdatascience.com/@julianh</td>\n",
       "      <td>julianherrera</td>\n",
       "      <td>towardsdatascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The End of the World</td>\n",
       "      <td>Below is a conversation I had with OpenAIs GPT-3s language model. I gave GPT-3 the role of Wise Being. All of the</td>\n",
       "      <td>1</td>\n",
       "      <td>Kirk Ouimet</td>\n",
       "      <td>No publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>AI</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@kirkouimet/the-end-of-the-world-5457c252523</td>\n",
       "      <td>https://medium.com/@kirkouimet</td>\n",
       "      <td>kirkouimet</td>\n",
       "      <td>nopublication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    How to go from BayesTheorem to Bayesian Inference   \n",
       "1  Autoencoders: Overview of Research and Applications   \n",
       "2  Regarding SingularityNET and the Recent KuCoin Hack   \n",
       "3         Understand Machine Learning with One Article   \n",
       "4                                 The End of the World   \n",
       "\n",
       "                                                                                                            Subtitle  \\\n",
       "0                                                                                                        No subtitle   \n",
       "1                                                                                                        No subtitle   \n",
       "2                                                                                                        No subtitle   \n",
       "3                                                           Lets dive into one of the most mind-blowing and demanded   \n",
       "4  Below is a conversation I had with OpenAIs GPT-3s language model. I gave GPT-3 the role of Wise Being. All of the   \n",
       "\n",
       "   Image               Author           Publication  Year  Month  Day Tag  \\\n",
       "0      1             JimSpark  Towards Data Science  2020     10    1  AI   \n",
       "1      1  Branislav Holl nder  Towards Data Science  2020     10    1  AI   \n",
       "2      1         Ben Goertzel        SingularityNET  2020     10    1  AI   \n",
       "3      1       Julian Herrera  Towards Data Science  2020     10    1  AI   \n",
       "4      1          Kirk Ouimet        No publication  2020     10    1  AI   \n",
       "\n",
       "   Reading_Time  Claps  Comment  \\\n",
       "0            10   68.0        0   \n",
       "1            10  129.0        0   \n",
       "2             8  320.0        0   \n",
       "3            11   67.0        0   \n",
       "4             5   60.0        0   \n",
       "\n",
       "                                                                                               url  \\\n",
       "0    https://towardsdatascience.com/how-to-go-from-bayestheorem-to-bayesian-inference-2a75ac64ec07   \n",
       "1   https://towardsdatascience.com/autoencoders-overview-of-research-and-applications-86135f7c0d35   \n",
       "2  https://blog.singularitynet.io/regarding-singularitynet-and-the-recent-kucoin-hack-fee601b8ad8c   \n",
       "3         https://towardsdatascience.com/understand-machine-learning-with-one-article-7399f6b9c5ad   \n",
       "4                                  https://medium.com/@kirkouimet/the-end-of-the-world-5457c252523   \n",
       "\n",
       "                                            Author_url       Author_clean  \\\n",
       "0            https://towardsdatascience.com/@jimip6c12           jimspark   \n",
       "1  https://towardsdatascience.com/@branislav.hollander  branislavhollnder   \n",
       "2            https://blog.singularitynet.io/@ben_90344        bengoertzel   \n",
       "3              https://towardsdatascience.com/@julianh      julianherrera   \n",
       "4                       https://medium.com/@kirkouimet         kirkouimet   \n",
       "\n",
       "    Publication_clean  \n",
       "0  towardsdatascience  \n",
       "1  towardsdatascience  \n",
       "2      singularitynet  \n",
       "3  towardsdatascience  \n",
       "4       nopublication  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-illinois",
   "metadata": {},
   "source": [
    "### Criando campo com os metadados necessários para vetorização\n",
    "Agora iremos criar um campo no dataframe contendo todos os metadados (autor, publicação e título) que serão utilizados na vetorização. A função **create_soup** irá juntar as variáveis necessárias, separadas por um espaço em branco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rough-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return x['Title'] + ' ' + x['Author_clean'] + ' '+ x['Publication_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "australian-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a nova feature 'soup', para guardar os metadados para vetorização\n",
    "articles_dec['soup'] = articles_dec.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "quarterly-partnership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to go from BayesTheorem to Bayesian Inference jimspark towardsdatascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autoencoders: Overview of Research and Applications branislavhollnder towardsdatascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regarding SingularityNET and the Recent KuCoin Hack bengoertzel singularitynet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understand Machine Learning with One Article julianherrera towardsdatascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The End of the World kirkouimet nopublication</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       soup\n",
       "0             How to go from BayesTheorem to Bayesian Inference jimspark towardsdatascience\n",
       "1  Autoencoders: Overview of Research and Applications branislavhollnder towardsdatascience\n",
       "2            Regarding SingularityNET and the Recent KuCoin Hack bengoertzel singularitynet\n",
       "3             Understand Machine Learning with One Article julianherrera towardsdatascience\n",
       "4                                             The End of the World kirkouimet nopublication"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_dec[['soup']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-provision",
   "metadata": {},
   "source": [
    "Construindo a matriz TF-IDF, através do treino e transformação do corpus, e checando seu shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "smart-mobile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33472, 193702)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_2 = tfidf.fit_transform(articles_dec['soup'])\n",
    "tfidf_matrix_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "nonprofit-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33472, 33472)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computando a matriz de similaridades e verificando o shape\n",
    "cosine_sim2 = cosine_similarity(tfidf_matrix_2)\n",
    "cosine_sim2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "applied-chrome",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mArtigo pesquisado:\u001b[0m The Roadmap of Mathematics for Deep Learning\n",
      "\u001b[1mAutor:\u001b[0m Tivadar Danka\n",
      "\u001b[1mPublicação:\u001b[0m Towards Data Science\n",
      "\n",
      "\u001b[91m\u001b[1mTop 10 artigos recomendados:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Claps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27102</th>\n",
       "      <td>The Mathematics Behind Deep Learning</td>\n",
       "      <td>Trist'n Joseph</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31055</th>\n",
       "      <td>Education or Experience? Both.</td>\n",
       "      <td>Tivadar Danka</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>The Mathematics of Deep Learning Optimizations- part 2</td>\n",
       "      <td>Charlie Masters</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>The Mathematics of Deep-learning Optimisations- part 1</td>\n",
       "      <td>Charlie Masters</td>\n",
       "      <td>Becoming Human: Artificial Intelligence Magazine</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>How to compress a neural network</td>\n",
       "      <td>Tivadar Danka</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>Can a neural network train other networks?</td>\n",
       "      <td>Tivadar Danka</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27715</th>\n",
       "      <td>Do Machine Learning Like an Experimental Scientist</td>\n",
       "      <td>Tivadar Danka</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30149</th>\n",
       "      <td>The Way of Monetizing Your Code Is Changing</td>\n",
       "      <td>Tivadar Danka</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30390</th>\n",
       "      <td>The 3 Best Free Online Resources to Learn MLOps</td>\n",
       "      <td>Tivadar Danka</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11857</th>\n",
       "      <td>Complete Deep Learning Roadmap</td>\n",
       "      <td>Akash kumar</td>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Title  \\\n",
       "27102                    The Mathematics Behind Deep Learning   \n",
       "31055                          Education or Experience? Both.   \n",
       "9286   The Mathematics of Deep Learning Optimizations- part 2   \n",
       "9288   The Mathematics of Deep-learning Optimisations- part 1   \n",
       "338                          How to compress a neural network   \n",
       "4315               Can a neural network train other networks?   \n",
       "27715      Do Machine Learning Like an Experimental Scientist   \n",
       "30149             The Way of Monetizing Your Code Is Changing   \n",
       "30390         The 3 Best Free Online Resources to Learn MLOps   \n",
       "11857                          Complete Deep Learning Roadmap   \n",
       "\n",
       "                Author                                       Publication  \\\n",
       "27102   Trist'n Joseph                              Towards Data Science   \n",
       "31055    Tivadar Danka                              Towards Data Science   \n",
       "9286   Charlie Masters  Becoming Human: Artificial Intelligence Magazine   \n",
       "9288   Charlie Masters  Becoming Human: Artificial Intelligence Magazine   \n",
       "338      Tivadar Danka                              Towards Data Science   \n",
       "4315     Tivadar Danka                              Towards Data Science   \n",
       "27715    Tivadar Danka                              Towards Data Science   \n",
       "30149    Tivadar Danka                              Towards Data Science   \n",
       "30390    Tivadar Danka                              Towards Data Science   \n",
       "11857      Akash kumar                                  Analytics Vidhya   \n",
       "\n",
       "       Claps  \n",
       "27102  311.0  \n",
       "31055    5.0  \n",
       "9286    55.0  \n",
       "9288    60.0  \n",
       "338    283.0  \n",
       "4315   265.0  \n",
       "27715   15.0  \n",
       "30149   51.0  \n",
       "30390  136.0  \n",
       "11857   10.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Roadmap of Mathematics for Deep Learning', cosine_sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-crime",
   "metadata": {},
   "source": [
    "Com a inserção de autor e publicação o recomendador parece ter ficado mais tendencioso a trazer artigos do mesmo autor na mesma publicação. É uma outra visão que pode funcionar bem em casos que a pessoa opte dar preferência a ver mais artigos do mesmo autor e/ou publicação. O primeiro recomendador pode funcionar bem no caso em que a intenção seja variar nos casos dos autores e/ou publicações atrelados aos artigos sugeridos.\n",
    "### Conclusão\n",
    "Esta foi uma aplicação de como criar uma feramenta simples para recomendação de artigos divulgados no Medium. Foram criados dois recomendadores, um utilizando apenas os títulos dos artigos para calcular as similaridades e outro utilizando, também, autor e publicação. Observamos que cada um pode ter uma aplicação, dependendo de determinado objetivo de negócio. Neste caso, ficamos limitados aos dados obtidos através da raspagem no site do Medium, claro que novas informações podem ajudar a melhorar o recomendador e até utilizar uma abordagem de filtro colaborativo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
